{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **TextBlob**\n",
        "\n",
        "TextBlob provides a wide range of methods for natural language processing tasks. Below are some of the key methods and functions available in TextBlob:"
      ],
      "metadata": {
        "id": "UP7s8LxC-oEy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbQcVSauL0PR",
        "outputId": "0a063391-1d96-4f7f-e647-91ccd56186c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import textblob\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "CnXg1KVJZidq",
        "outputId": "42bbef29-cc26-4dee-f30d-a8ee3a922935",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str = '''SHOULD WE COLONISE SPACE?\n",
        "\n",
        "        In conclusion, I return to Einstein. If we find a planet in the\n",
        "        Alpha Centauri system, its image, captured by a camera travelling\n",
        "        at a fifth of light speed, will be slightly distorted due to the\n",
        "        effects of special relativity. It would be the first time a\n",
        "        spacecraft has flown fast enough to see such effects. In fact,\n",
        "        Einstein’s theory is central to the whole mission. Without it\n",
        "        we would have neither lasers nor the ability to perform the\n",
        "        calculations necessary for guidance, imaging and data transmission\n",
        "        over twenty-five trillion miles at a fifth of light speed. We can\n",
        "        see a pathway between that sixteen-year-old boy dreaming of riding\n",
        "        on a light beam and our own dream, which we are planning to turn\n",
        "        into a reality, of riding our own light beam to the stars. We are\n",
        "        standing at the threshold of a new era. Human colonisation on other\n",
        "        planets is no longer science fiction. It can be science fact. The\n",
        "        human race has existed as a separate species for about two million\n",
        "        years. Civilisation began about 10,000 years ago, and the rate of\n",
        "        development has been steadily increasing. If humanity is to continue\n",
        "        for another million years, our future lies in boldly going where no one\n",
        "        else has gone before. I hope for the best. I have to. We have no other\n",
        "        option. The era of civilian space travel is coming. What do you think\n",
        "        it means to us? I look forward to space travel. I would be one of the\n",
        "        first to buy a ticket. I expect that within the next hundred years we\n",
        "        will be able to travel anywhere in the solar system, except maybe the\n",
        "        outer planets. But travel to the stars will take a bit longer. I reckon\n",
        "        in 500 years, we will have visited some of the nearby stars. It won’t be\n",
        "        like Star Trek . We won’t be able to travel at warp speed. So a round trip\n",
        "        will take at least ten years and probably much longer.\n",
        "\n",
        "        From the book: Brief Answers to the Big Questions – Stephen Hawking\n",
        "'''"
      ],
      "metadata": {
        "id": "gt5HNmSuaeUS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Tokenization**\n",
        "   - `.words`: Splits the text into individual words.\n",
        "   - `.sentences`: Splits the text into individual sentences.\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "Ev_9-ZFf-1vn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob = textblob.TextBlob(str)\n",
        "a = blob.words\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcKU3ITKamfC",
        "outputId": "cc9c3b03-7dfd-4fef-e300-e33ee1f6a8b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SHOULD', 'WE', 'COLONISE', 'SPACE', 'In', 'conclusion', 'I', 'return', 'to', 'Einstein', 'If', 'we', 'find', 'a', 'planet', 'in', 'the', 'Alpha', 'Centauri', 'system', 'its', 'image', 'captured', 'by', 'a', 'camera', 'travelling', 'at', 'a', 'fifth', 'of', 'light', 'speed', 'will', 'be', 'slightly', 'distorted', 'due', 'to', 'the', 'effects', 'of', 'special', 'relativity', 'It', 'would', 'be', 'the', 'first', 'time', 'a', 'spacecraft', 'has', 'flown', 'fast', 'enough', 'to', 'see', 'such', 'effects', 'In', 'fact', 'Einstein', '’', 's', 'theory', 'is', 'central', 'to', 'the', 'whole', 'mission', 'Without', 'it', 'we', 'would', 'have', 'neither', 'lasers', 'nor', 'the', 'ability', 'to', 'perform', 'the', 'calculations', 'necessary', 'for', 'guidance', 'imaging', 'and', 'data', 'transmission', 'over', 'twenty-five', 'trillion', 'miles', 'at', 'a', 'fifth', 'of', 'light', 'speed', 'We', 'can', 'see', 'a', 'pathway', 'between', 'that', 'sixteen-year-old', 'boy', 'dreaming', 'of', 'riding', 'on', 'a', 'light', 'beam', 'and', 'our', 'own', 'dream', 'which', 'we', 'are', 'planning', 'to', 'turn', 'into', 'a', 'reality', 'of', 'riding', 'our', 'own', 'light', 'beam', 'to', 'the', 'stars', 'We', 'are', 'standing', 'at', 'the', 'threshold', 'of', 'a', 'new', 'era', 'Human', 'colonisation', 'on', 'other', 'planets', 'is', 'no', 'longer', 'science', 'fiction', 'It', 'can', 'be', 'science', 'fact', 'The', 'human', 'race', 'has', 'existed', 'as', 'a', 'separate', 'species', 'for', 'about', 'two', 'million', 'years', 'Civilisation', 'began', 'about', '10,000', 'years', 'ago', 'and', 'the', 'rate', 'of', 'development', 'has', 'been', 'steadily', 'increasing', 'If', 'humanity', 'is', 'to', 'continue', 'for', 'another', 'million', 'years', 'our', 'future', 'lies', 'in', 'boldly', 'going', 'where', 'no', 'one', 'else', 'has', 'gone', 'before', 'I', 'hope', 'for', 'the', 'best', 'I', 'have', 'to', 'We', 'have', 'no', 'other', 'option', 'The', 'era', 'of', 'civilian', 'space', 'travel', 'is', 'coming', 'What', 'do', 'you', 'think', 'it', 'means', 'to', 'us', 'I', 'look', 'forward', 'to', 'space', 'travel', 'I', 'would', 'be', 'one', 'of', 'the', 'first', 'to', 'buy', 'a', 'ticket', 'I', 'expect', 'that', 'within', 'the', 'next', 'hundred', 'years', 'we', 'will', 'be', 'able', 'to', 'travel', 'anywhere', 'in', 'the', 'solar', 'system', 'except', 'maybe', 'the', 'outer', 'planets', 'But', 'travel', 'to', 'the', 'stars', 'will', 'take', 'a', 'bit', 'longer', 'I', 'reckon', 'in', '500', 'years', 'we', 'will', 'have', 'visited', 'some', 'of', 'the', 'nearby', 'stars', 'It', 'won', '’', 't', 'be', 'like', 'Star', 'Trek', 'We', 'won', '’', 't', 'be', 'able', 'to', 'travel', 'at', 'warp', 'speed', 'So', 'a', 'round', 'trip', 'will', 'take', 'at', 'least', 'ten', 'years', 'and', 'probably', 'much', 'longer', 'From', 'the', 'book', 'Brief', 'Answers', 'to', 'the', 'Big', 'Questions', '–', 'Stephen', 'Hawking']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = blob.sentences\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxcEC-4zbHYA",
        "outputId": "7b05b1cd-e218-4409-9e42-219fd86adad5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Sentence(\"SHOULD WE COLONISE SPACE?\"), Sentence(\"In conclusion, I return to Einstein.\"), Sentence(\"If we find a planet in the\n",
            "        Alpha Centauri system, its image, captured by a camera travelling\n",
            "        at a fifth of light speed, will be slightly distorted due to the\n",
            "        effects of special relativity.\"), Sentence(\"It would be the first time a\n",
            "        spacecraft has flown fast enough to see such effects.\"), Sentence(\"In fact,\n",
            "        Einstein’s theory is central to the whole mission.\"), Sentence(\"Without it\n",
            "        we would have neither lasers nor the ability to perform the\n",
            "        calculations necessary for guidance, imaging and data transmission\n",
            "        over twenty-five trillion miles at a fifth of light speed.\"), Sentence(\"We can\n",
            "        see a pathway between that sixteen-year-old boy dreaming of riding\n",
            "        on a light beam and our own dream, which we are planning to turn\n",
            "        into a reality, of riding our own light beam to the stars.\"), Sentence(\"We are\n",
            "        standing at the threshold of a new era.\"), Sentence(\"Human colonisation on other\n",
            "        planets is no longer science fiction.\"), Sentence(\"It can be science fact.\"), Sentence(\"The\n",
            "        human race has existed as a separate species for about two million\n",
            "        years.\"), Sentence(\"Civilisation began about 10,000 years ago, and the rate of\n",
            "        development has been steadily increasing.\"), Sentence(\"If humanity is to continue\n",
            "        for another million years, our future lies in boldly going where no one\n",
            "        else has gone before.\"), Sentence(\"I hope for the best.\"), Sentence(\"I have to.\"), Sentence(\"We have no other\n",
            "        option.\"), Sentence(\"The era of civilian space travel is coming.\"), Sentence(\"What do you think\n",
            "        it means to us?\"), Sentence(\"I look forward to space travel.\"), Sentence(\"I would be one of the\n",
            "        first to buy a ticket.\"), Sentence(\"I expect that within the next hundred years we\n",
            "        will be able to travel anywhere in the solar system, except maybe the\n",
            "        outer planets.\"), Sentence(\"But travel to the stars will take a bit longer.\"), Sentence(\"I reckon\n",
            "        in 500 years, we will have visited some of the nearby stars.\"), Sentence(\"It won’t be\n",
            "        like Star Trek .\"), Sentence(\"We won’t be able to travel at warp speed.\"), Sentence(\"So a round trip\n",
            "        will take at least ten years and probably much longer.\"), Sentence(\"From the book: Brief Answers to the Big Questions – Stephen Hawking\")]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. ngram**\n",
        "\n",
        "The `.ngrams(n)` method in **TextBlob** generates **n-grams** from the text, where an n-gram is a contiguous sequence of `n` items (typically words) from a given text.\n",
        "\n",
        "### How It Works:\n",
        "- A **unigram** (1-gram) contains individual words.\n",
        "- A **bigram** (2-gram) contains pairs of consecutive words.\n",
        "- A **trigram** (3-gram) contains sequences of three consecutive words, and so on.\n",
        "\n",
        "### Usage:\n",
        "\n",
        "You can use `.ngrams(n)` for:\n",
        "- **Text analysis**: Capture relationships between adjacent words.\n",
        "- **Feature extraction**: Create features for machine learning models based on sequences of words.\n",
        "- **Language modeling**: Identify common phrases or word patterns in a corpus.\n",
        "\n",
        "You can adjust `n` to get trigrams (`n=3`), four-grams (`n=4`), and so on depending on how long the sequences need to be."
      ],
      "metadata": {
        "id": "S29qK8me_phn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jLLJOs4c_pM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = blob.ngrams(n=4)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bnxYPGybQRJ",
        "outputId": "6e8ee8ed-d4bc-47d8-eedd-f0d6cae576e0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[WordList(['SHOULD', 'WE', 'COLONISE', 'SPACE']), WordList(['WE', 'COLONISE', 'SPACE', 'In']), WordList(['COLONISE', 'SPACE', 'In', 'conclusion']), WordList(['SPACE', 'In', 'conclusion', 'I']), WordList(['In', 'conclusion', 'I', 'return']), WordList(['conclusion', 'I', 'return', 'to']), WordList(['I', 'return', 'to', 'Einstein']), WordList(['return', 'to', 'Einstein', 'If']), WordList(['to', 'Einstein', 'If', 'we']), WordList(['Einstein', 'If', 'we', 'find']), WordList(['If', 'we', 'find', 'a']), WordList(['we', 'find', 'a', 'planet']), WordList(['find', 'a', 'planet', 'in']), WordList(['a', 'planet', 'in', 'the']), WordList(['planet', 'in', 'the', 'Alpha']), WordList(['in', 'the', 'Alpha', 'Centauri']), WordList(['the', 'Alpha', 'Centauri', 'system']), WordList(['Alpha', 'Centauri', 'system', 'its']), WordList(['Centauri', 'system', 'its', 'image']), WordList(['system', 'its', 'image', 'captured']), WordList(['its', 'image', 'captured', 'by']), WordList(['image', 'captured', 'by', 'a']), WordList(['captured', 'by', 'a', 'camera']), WordList(['by', 'a', 'camera', 'travelling']), WordList(['a', 'camera', 'travelling', 'at']), WordList(['camera', 'travelling', 'at', 'a']), WordList(['travelling', 'at', 'a', 'fifth']), WordList(['at', 'a', 'fifth', 'of']), WordList(['a', 'fifth', 'of', 'light']), WordList(['fifth', 'of', 'light', 'speed']), WordList(['of', 'light', 'speed', 'will']), WordList(['light', 'speed', 'will', 'be']), WordList(['speed', 'will', 'be', 'slightly']), WordList(['will', 'be', 'slightly', 'distorted']), WordList(['be', 'slightly', 'distorted', 'due']), WordList(['slightly', 'distorted', 'due', 'to']), WordList(['distorted', 'due', 'to', 'the']), WordList(['due', 'to', 'the', 'effects']), WordList(['to', 'the', 'effects', 'of']), WordList(['the', 'effects', 'of', 'special']), WordList(['effects', 'of', 'special', 'relativity']), WordList(['of', 'special', 'relativity', 'It']), WordList(['special', 'relativity', 'It', 'would']), WordList(['relativity', 'It', 'would', 'be']), WordList(['It', 'would', 'be', 'the']), WordList(['would', 'be', 'the', 'first']), WordList(['be', 'the', 'first', 'time']), WordList(['the', 'first', 'time', 'a']), WordList(['first', 'time', 'a', 'spacecraft']), WordList(['time', 'a', 'spacecraft', 'has']), WordList(['a', 'spacecraft', 'has', 'flown']), WordList(['spacecraft', 'has', 'flown', 'fast']), WordList(['has', 'flown', 'fast', 'enough']), WordList(['flown', 'fast', 'enough', 'to']), WordList(['fast', 'enough', 'to', 'see']), WordList(['enough', 'to', 'see', 'such']), WordList(['to', 'see', 'such', 'effects']), WordList(['see', 'such', 'effects', 'In']), WordList(['such', 'effects', 'In', 'fact']), WordList(['effects', 'In', 'fact', 'Einstein']), WordList(['In', 'fact', 'Einstein', '’']), WordList(['fact', 'Einstein', '’', 's']), WordList(['Einstein', '’', 's', 'theory']), WordList(['’', 's', 'theory', 'is']), WordList(['s', 'theory', 'is', 'central']), WordList(['theory', 'is', 'central', 'to']), WordList(['is', 'central', 'to', 'the']), WordList(['central', 'to', 'the', 'whole']), WordList(['to', 'the', 'whole', 'mission']), WordList(['the', 'whole', 'mission', 'Without']), WordList(['whole', 'mission', 'Without', 'it']), WordList(['mission', 'Without', 'it', 'we']), WordList(['Without', 'it', 'we', 'would']), WordList(['it', 'we', 'would', 'have']), WordList(['we', 'would', 'have', 'neither']), WordList(['would', 'have', 'neither', 'lasers']), WordList(['have', 'neither', 'lasers', 'nor']), WordList(['neither', 'lasers', 'nor', 'the']), WordList(['lasers', 'nor', 'the', 'ability']), WordList(['nor', 'the', 'ability', 'to']), WordList(['the', 'ability', 'to', 'perform']), WordList(['ability', 'to', 'perform', 'the']), WordList(['to', 'perform', 'the', 'calculations']), WordList(['perform', 'the', 'calculations', 'necessary']), WordList(['the', 'calculations', 'necessary', 'for']), WordList(['calculations', 'necessary', 'for', 'guidance']), WordList(['necessary', 'for', 'guidance', 'imaging']), WordList(['for', 'guidance', 'imaging', 'and']), WordList(['guidance', 'imaging', 'and', 'data']), WordList(['imaging', 'and', 'data', 'transmission']), WordList(['and', 'data', 'transmission', 'over']), WordList(['data', 'transmission', 'over', 'twenty-five']), WordList(['transmission', 'over', 'twenty-five', 'trillion']), WordList(['over', 'twenty-five', 'trillion', 'miles']), WordList(['twenty-five', 'trillion', 'miles', 'at']), WordList(['trillion', 'miles', 'at', 'a']), WordList(['miles', 'at', 'a', 'fifth']), WordList(['at', 'a', 'fifth', 'of']), WordList(['a', 'fifth', 'of', 'light']), WordList(['fifth', 'of', 'light', 'speed']), WordList(['of', 'light', 'speed', 'We']), WordList(['light', 'speed', 'We', 'can']), WordList(['speed', 'We', 'can', 'see']), WordList(['We', 'can', 'see', 'a']), WordList(['can', 'see', 'a', 'pathway']), WordList(['see', 'a', 'pathway', 'between']), WordList(['a', 'pathway', 'between', 'that']), WordList(['pathway', 'between', 'that', 'sixteen-year-old']), WordList(['between', 'that', 'sixteen-year-old', 'boy']), WordList(['that', 'sixteen-year-old', 'boy', 'dreaming']), WordList(['sixteen-year-old', 'boy', 'dreaming', 'of']), WordList(['boy', 'dreaming', 'of', 'riding']), WordList(['dreaming', 'of', 'riding', 'on']), WordList(['of', 'riding', 'on', 'a']), WordList(['riding', 'on', 'a', 'light']), WordList(['on', 'a', 'light', 'beam']), WordList(['a', 'light', 'beam', 'and']), WordList(['light', 'beam', 'and', 'our']), WordList(['beam', 'and', 'our', 'own']), WordList(['and', 'our', 'own', 'dream']), WordList(['our', 'own', 'dream', 'which']), WordList(['own', 'dream', 'which', 'we']), WordList(['dream', 'which', 'we', 'are']), WordList(['which', 'we', 'are', 'planning']), WordList(['we', 'are', 'planning', 'to']), WordList(['are', 'planning', 'to', 'turn']), WordList(['planning', 'to', 'turn', 'into']), WordList(['to', 'turn', 'into', 'a']), WordList(['turn', 'into', 'a', 'reality']), WordList(['into', 'a', 'reality', 'of']), WordList(['a', 'reality', 'of', 'riding']), WordList(['reality', 'of', 'riding', 'our']), WordList(['of', 'riding', 'our', 'own']), WordList(['riding', 'our', 'own', 'light']), WordList(['our', 'own', 'light', 'beam']), WordList(['own', 'light', 'beam', 'to']), WordList(['light', 'beam', 'to', 'the']), WordList(['beam', 'to', 'the', 'stars']), WordList(['to', 'the', 'stars', 'We']), WordList(['the', 'stars', 'We', 'are']), WordList(['stars', 'We', 'are', 'standing']), WordList(['We', 'are', 'standing', 'at']), WordList(['are', 'standing', 'at', 'the']), WordList(['standing', 'at', 'the', 'threshold']), WordList(['at', 'the', 'threshold', 'of']), WordList(['the', 'threshold', 'of', 'a']), WordList(['threshold', 'of', 'a', 'new']), WordList(['of', 'a', 'new', 'era']), WordList(['a', 'new', 'era', 'Human']), WordList(['new', 'era', 'Human', 'colonisation']), WordList(['era', 'Human', 'colonisation', 'on']), WordList(['Human', 'colonisation', 'on', 'other']), WordList(['colonisation', 'on', 'other', 'planets']), WordList(['on', 'other', 'planets', 'is']), WordList(['other', 'planets', 'is', 'no']), WordList(['planets', 'is', 'no', 'longer']), WordList(['is', 'no', 'longer', 'science']), WordList(['no', 'longer', 'science', 'fiction']), WordList(['longer', 'science', 'fiction', 'It']), WordList(['science', 'fiction', 'It', 'can']), WordList(['fiction', 'It', 'can', 'be']), WordList(['It', 'can', 'be', 'science']), WordList(['can', 'be', 'science', 'fact']), WordList(['be', 'science', 'fact', 'The']), WordList(['science', 'fact', 'The', 'human']), WordList(['fact', 'The', 'human', 'race']), WordList(['The', 'human', 'race', 'has']), WordList(['human', 'race', 'has', 'existed']), WordList(['race', 'has', 'existed', 'as']), WordList(['has', 'existed', 'as', 'a']), WordList(['existed', 'as', 'a', 'separate']), WordList(['as', 'a', 'separate', 'species']), WordList(['a', 'separate', 'species', 'for']), WordList(['separate', 'species', 'for', 'about']), WordList(['species', 'for', 'about', 'two']), WordList(['for', 'about', 'two', 'million']), WordList(['about', 'two', 'million', 'years']), WordList(['two', 'million', 'years', 'Civilisation']), WordList(['million', 'years', 'Civilisation', 'began']), WordList(['years', 'Civilisation', 'began', 'about']), WordList(['Civilisation', 'began', 'about', '10,000']), WordList(['began', 'about', '10,000', 'years']), WordList(['about', '10,000', 'years', 'ago']), WordList(['10,000', 'years', 'ago', 'and']), WordList(['years', 'ago', 'and', 'the']), WordList(['ago', 'and', 'the', 'rate']), WordList(['and', 'the', 'rate', 'of']), WordList(['the', 'rate', 'of', 'development']), WordList(['rate', 'of', 'development', 'has']), WordList(['of', 'development', 'has', 'been']), WordList(['development', 'has', 'been', 'steadily']), WordList(['has', 'been', 'steadily', 'increasing']), WordList(['been', 'steadily', 'increasing', 'If']), WordList(['steadily', 'increasing', 'If', 'humanity']), WordList(['increasing', 'If', 'humanity', 'is']), WordList(['If', 'humanity', 'is', 'to']), WordList(['humanity', 'is', 'to', 'continue']), WordList(['is', 'to', 'continue', 'for']), WordList(['to', 'continue', 'for', 'another']), WordList(['continue', 'for', 'another', 'million']), WordList(['for', 'another', 'million', 'years']), WordList(['another', 'million', 'years', 'our']), WordList(['million', 'years', 'our', 'future']), WordList(['years', 'our', 'future', 'lies']), WordList(['our', 'future', 'lies', 'in']), WordList(['future', 'lies', 'in', 'boldly']), WordList(['lies', 'in', 'boldly', 'going']), WordList(['in', 'boldly', 'going', 'where']), WordList(['boldly', 'going', 'where', 'no']), WordList(['going', 'where', 'no', 'one']), WordList(['where', 'no', 'one', 'else']), WordList(['no', 'one', 'else', 'has']), WordList(['one', 'else', 'has', 'gone']), WordList(['else', 'has', 'gone', 'before']), WordList(['has', 'gone', 'before', 'I']), WordList(['gone', 'before', 'I', 'hope']), WordList(['before', 'I', 'hope', 'for']), WordList(['I', 'hope', 'for', 'the']), WordList(['hope', 'for', 'the', 'best']), WordList(['for', 'the', 'best', 'I']), WordList(['the', 'best', 'I', 'have']), WordList(['best', 'I', 'have', 'to']), WordList(['I', 'have', 'to', 'We']), WordList(['have', 'to', 'We', 'have']), WordList(['to', 'We', 'have', 'no']), WordList(['We', 'have', 'no', 'other']), WordList(['have', 'no', 'other', 'option']), WordList(['no', 'other', 'option', 'The']), WordList(['other', 'option', 'The', 'era']), WordList(['option', 'The', 'era', 'of']), WordList(['The', 'era', 'of', 'civilian']), WordList(['era', 'of', 'civilian', 'space']), WordList(['of', 'civilian', 'space', 'travel']), WordList(['civilian', 'space', 'travel', 'is']), WordList(['space', 'travel', 'is', 'coming']), WordList(['travel', 'is', 'coming', 'What']), WordList(['is', 'coming', 'What', 'do']), WordList(['coming', 'What', 'do', 'you']), WordList(['What', 'do', 'you', 'think']), WordList(['do', 'you', 'think', 'it']), WordList(['you', 'think', 'it', 'means']), WordList(['think', 'it', 'means', 'to']), WordList(['it', 'means', 'to', 'us']), WordList(['means', 'to', 'us', 'I']), WordList(['to', 'us', 'I', 'look']), WordList(['us', 'I', 'look', 'forward']), WordList(['I', 'look', 'forward', 'to']), WordList(['look', 'forward', 'to', 'space']), WordList(['forward', 'to', 'space', 'travel']), WordList(['to', 'space', 'travel', 'I']), WordList(['space', 'travel', 'I', 'would']), WordList(['travel', 'I', 'would', 'be']), WordList(['I', 'would', 'be', 'one']), WordList(['would', 'be', 'one', 'of']), WordList(['be', 'one', 'of', 'the']), WordList(['one', 'of', 'the', 'first']), WordList(['of', 'the', 'first', 'to']), WordList(['the', 'first', 'to', 'buy']), WordList(['first', 'to', 'buy', 'a']), WordList(['to', 'buy', 'a', 'ticket']), WordList(['buy', 'a', 'ticket', 'I']), WordList(['a', 'ticket', 'I', 'expect']), WordList(['ticket', 'I', 'expect', 'that']), WordList(['I', 'expect', 'that', 'within']), WordList(['expect', 'that', 'within', 'the']), WordList(['that', 'within', 'the', 'next']), WordList(['within', 'the', 'next', 'hundred']), WordList(['the', 'next', 'hundred', 'years']), WordList(['next', 'hundred', 'years', 'we']), WordList(['hundred', 'years', 'we', 'will']), WordList(['years', 'we', 'will', 'be']), WordList(['we', 'will', 'be', 'able']), WordList(['will', 'be', 'able', 'to']), WordList(['be', 'able', 'to', 'travel']), WordList(['able', 'to', 'travel', 'anywhere']), WordList(['to', 'travel', 'anywhere', 'in']), WordList(['travel', 'anywhere', 'in', 'the']), WordList(['anywhere', 'in', 'the', 'solar']), WordList(['in', 'the', 'solar', 'system']), WordList(['the', 'solar', 'system', 'except']), WordList(['solar', 'system', 'except', 'maybe']), WordList(['system', 'except', 'maybe', 'the']), WordList(['except', 'maybe', 'the', 'outer']), WordList(['maybe', 'the', 'outer', 'planets']), WordList(['the', 'outer', 'planets', 'But']), WordList(['outer', 'planets', 'But', 'travel']), WordList(['planets', 'But', 'travel', 'to']), WordList(['But', 'travel', 'to', 'the']), WordList(['travel', 'to', 'the', 'stars']), WordList(['to', 'the', 'stars', 'will']), WordList(['the', 'stars', 'will', 'take']), WordList(['stars', 'will', 'take', 'a']), WordList(['will', 'take', 'a', 'bit']), WordList(['take', 'a', 'bit', 'longer']), WordList(['a', 'bit', 'longer', 'I']), WordList(['bit', 'longer', 'I', 'reckon']), WordList(['longer', 'I', 'reckon', 'in']), WordList(['I', 'reckon', 'in', '500']), WordList(['reckon', 'in', '500', 'years']), WordList(['in', '500', 'years', 'we']), WordList(['500', 'years', 'we', 'will']), WordList(['years', 'we', 'will', 'have']), WordList(['we', 'will', 'have', 'visited']), WordList(['will', 'have', 'visited', 'some']), WordList(['have', 'visited', 'some', 'of']), WordList(['visited', 'some', 'of', 'the']), WordList(['some', 'of', 'the', 'nearby']), WordList(['of', 'the', 'nearby', 'stars']), WordList(['the', 'nearby', 'stars', 'It']), WordList(['nearby', 'stars', 'It', 'won']), WordList(['stars', 'It', 'won', '’']), WordList(['It', 'won', '’', 't']), WordList(['won', '’', 't', 'be']), WordList(['’', 't', 'be', 'like']), WordList(['t', 'be', 'like', 'Star']), WordList(['be', 'like', 'Star', 'Trek']), WordList(['like', 'Star', 'Trek', 'We']), WordList(['Star', 'Trek', 'We', 'won']), WordList(['Trek', 'We', 'won', '’']), WordList(['We', 'won', '’', 't']), WordList(['won', '’', 't', 'be']), WordList(['’', 't', 'be', 'able']), WordList(['t', 'be', 'able', 'to']), WordList(['be', 'able', 'to', 'travel']), WordList(['able', 'to', 'travel', 'at']), WordList(['to', 'travel', 'at', 'warp']), WordList(['travel', 'at', 'warp', 'speed']), WordList(['at', 'warp', 'speed', 'So']), WordList(['warp', 'speed', 'So', 'a']), WordList(['speed', 'So', 'a', 'round']), WordList(['So', 'a', 'round', 'trip']), WordList(['a', 'round', 'trip', 'will']), WordList(['round', 'trip', 'will', 'take']), WordList(['trip', 'will', 'take', 'at']), WordList(['will', 'take', 'at', 'least']), WordList(['take', 'at', 'least', 'ten']), WordList(['at', 'least', 'ten', 'years']), WordList(['least', 'ten', 'years', 'and']), WordList(['ten', 'years', 'and', 'probably']), WordList(['years', 'and', 'probably', 'much']), WordList(['and', 'probably', 'much', 'longer']), WordList(['probably', 'much', 'longer', 'From']), WordList(['much', 'longer', 'From', 'the']), WordList(['longer', 'From', 'the', 'book']), WordList(['From', 'the', 'book', 'Brief']), WordList(['the', 'book', 'Brief', 'Answers']), WordList(['book', 'Brief', 'Answers', 'to']), WordList(['Brief', 'Answers', 'to', 'the']), WordList(['Answers', 'to', 'the', 'Big']), WordList(['to', 'the', 'Big', 'Questions']), WordList(['the', 'Big', 'Questions', '–']), WordList(['Big', 'Questions', '–', 'Stephen']), WordList(['Questions', '–', 'Stephen', 'Hawking'])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Word Definitions and Synonyms (via WordNet)**\n",
        "\n",
        "- .definitions: Returns definitions of words from WordNet.\n",
        "\n",
        "- .synsets: Returns a list of synonyms for a word"
      ],
      "metadata": {
        "id": "2d83l7mvAN7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import Word\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "a = Word(\"book\")\n",
        "print(a.definitions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OAnG-m1berN",
        "outputId": "c04967d6-1757-41a0-9497-cfb61a42835d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a written work or composition that has been published (printed on pages bound together)', 'physical objects consisting of a number of pages bound together', 'a compilation of the known facts regarding something or someone', 'a written version of a play or other dramatic composition; used in preparing for a performance', 'a record in which commercial accounts are recorded', 'a collection of playing cards satisfying the rules of a card game', 'a collection of rules or prescribed standards on the basis of which decisions are made', 'the sacred writings of Islam revealed by God to the prophet Muhammad during his life at Mecca and Medina', 'the sacred writings of the Christian religions', 'a major division of a long written composition', 'a number of sheets (ticket or stamps etc.) bound together on one edge', 'engage for a performance', 'arrange for and reserve (something for someone else) in advance', 'record a charge in a police register', 'register in a hotel booker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.synsets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moqYuCsbTE0U",
        "outputId": "2b96be46-770a-4d74-cdb5-25f8c95ea69d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Synset('book.n.01'),\n",
              " Synset('book.n.02'),\n",
              " Synset('record.n.05'),\n",
              " Synset('script.n.01'),\n",
              " Synset('ledger.n.01'),\n",
              " Synset('book.n.06'),\n",
              " Synset('book.n.07'),\n",
              " Synset('koran.n.01'),\n",
              " Synset('bible.n.01'),\n",
              " Synset('book.n.10'),\n",
              " Synset('book.n.11'),\n",
              " Synset('book.v.01'),\n",
              " Synset('reserve.v.04'),\n",
              " Synset('book.v.03'),\n",
              " Synset('book.v.04')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Word and Sentence Counts**\n",
        "\n",
        "\n",
        "- .word_counts: Returns a dictionary with word frequencies.\n",
        "\n",
        "- .sentence_count: Returns the number of sentences in the text"
      ],
      "metadata": {
        "id": "U4WUV3J7ApQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(blob.word_counts[\"space\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bArbexnOb4Gc",
        "outputId": "d2bcc3eb-26f3-46bc-f60d-d68086f96afa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Sentiment Analysis**\n",
        "   - `.sentiment`: Returns a named tuple `(polarity, subjectivity)` where:\n",
        "     - **Polarity** ranges from `-1` (negative) to `1` (positive).\n",
        "     - **Subjectivity** ranges from `0` (objective) to `1` (subjective).\n"
      ],
      "metadata": {
        "id": "dxLZWl71QSf0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = blob.sentiment\n",
        "\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB4OvURFc2Fe",
        "outputId": "c6bbad28-97af-456d-dfbc-9396741a3bcf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment(polarity=0.1725525664811379, subjectivity=0.44312306740878166)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **6. Part-of-Speech (POS) Tagging**\n",
        "\n",
        "-  .tags: Returns a list of tuples, where each tuple contains a word and its part of speech (POS) tag"
      ],
      "metadata": {
        "id": "lLgNX0I0RrKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textblob\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "blob.tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5Kp8G66Q7ij",
        "outputId": "d71adfd5-a93f-40c8-a96d-6529c4c78bf5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('SHOULD', 'MD'),\n",
              " ('WE', 'NNP'),\n",
              " ('COLONISE', 'NNP'),\n",
              " ('SPACE', 'NNP'),\n",
              " ('In', 'IN'),\n",
              " ('conclusion', 'NN'),\n",
              " ('I', 'PRP'),\n",
              " ('return', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('Einstein', 'NNP'),\n",
              " ('If', 'IN'),\n",
              " ('we', 'PRP'),\n",
              " ('find', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('planet', 'NN'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('Alpha', 'NNP'),\n",
              " ('Centauri', 'NNP'),\n",
              " ('system', 'NN'),\n",
              " ('its', 'PRP$'),\n",
              " ('image', 'NN'),\n",
              " ('captured', 'VBN'),\n",
              " ('by', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('camera', 'NN'),\n",
              " ('travelling', 'NN'),\n",
              " ('at', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('fifth', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('light', 'JJ'),\n",
              " ('speed', 'NN'),\n",
              " ('will', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('slightly', 'RB'),\n",
              " ('distorted', 'VBN'),\n",
              " ('due', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('effects', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('special', 'JJ'),\n",
              " ('relativity', 'NN'),\n",
              " ('It', 'PRP'),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('first', 'JJ'),\n",
              " ('time', 'NN'),\n",
              " ('a', 'DT'),\n",
              " ('spacecraft', 'NN'),\n",
              " ('has', 'VBZ'),\n",
              " ('flown', 'VBN'),\n",
              " ('fast', 'RB'),\n",
              " ('enough', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('see', 'VB'),\n",
              " ('such', 'JJ'),\n",
              " ('effects', 'NNS'),\n",
              " ('In', 'IN'),\n",
              " ('fact', 'NN'),\n",
              " ('Einstein', 'NNP'),\n",
              " ('’', 'NNP'),\n",
              " ('s', 'NN'),\n",
              " ('theory', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('central', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('whole', 'JJ'),\n",
              " ('mission', 'NN'),\n",
              " ('Without', 'IN'),\n",
              " ('it', 'PRP'),\n",
              " ('we', 'PRP'),\n",
              " ('would', 'MD'),\n",
              " ('have', 'VB'),\n",
              " ('neither', 'CC'),\n",
              " ('lasers', 'NNS'),\n",
              " ('nor', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('ability', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('perform', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('calculations', 'NNS'),\n",
              " ('necessary', 'JJ'),\n",
              " ('for', 'IN'),\n",
              " ('guidance', 'NN'),\n",
              " ('imaging', 'VBG'),\n",
              " ('and', 'CC'),\n",
              " ('data', 'NNS'),\n",
              " ('transmission', 'NN'),\n",
              " ('over', 'IN'),\n",
              " ('twenty-five', 'JJ'),\n",
              " ('trillion', 'CD'),\n",
              " ('miles', 'NNS'),\n",
              " ('at', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('fifth', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('light', 'JJ'),\n",
              " ('speed', 'NN'),\n",
              " ('We', 'PRP'),\n",
              " ('can', 'MD'),\n",
              " ('see', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('pathway', 'NN'),\n",
              " ('between', 'IN'),\n",
              " ('that', 'DT'),\n",
              " ('sixteen-year-old', 'JJ'),\n",
              " ('boy', 'NN'),\n",
              " ('dreaming', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('riding', 'VBG'),\n",
              " ('on', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('light', 'JJ'),\n",
              " ('beam', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('our', 'PRP$'),\n",
              " ('own', 'JJ'),\n",
              " ('dream', 'NN'),\n",
              " ('which', 'WDT'),\n",
              " ('we', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('planning', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('turn', 'VB'),\n",
              " ('into', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('reality', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('riding', 'VBG'),\n",
              " ('our', 'PRP$'),\n",
              " ('own', 'JJ'),\n",
              " ('light', 'NN'),\n",
              " ('beam', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('stars', 'NNS'),\n",
              " ('We', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('standing', 'VBG'),\n",
              " ('at', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('threshold', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('new', 'JJ'),\n",
              " ('era', 'NN'),\n",
              " ('Human', 'NNP'),\n",
              " ('colonisation', 'NN'),\n",
              " ('on', 'IN'),\n",
              " ('other', 'JJ'),\n",
              " ('planets', 'NNS'),\n",
              " ('is', 'VBZ'),\n",
              " ('no', 'DT'),\n",
              " ('longer', 'JJR'),\n",
              " ('science', 'NN'),\n",
              " ('fiction', 'NN'),\n",
              " ('It', 'PRP'),\n",
              " ('can', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('science', 'JJ'),\n",
              " ('fact', 'NN'),\n",
              " ('The', 'DT'),\n",
              " ('human', 'JJ'),\n",
              " ('race', 'NN'),\n",
              " ('has', 'VBZ'),\n",
              " ('existed', 'VBN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('separate', 'JJ'),\n",
              " ('species', 'NNS'),\n",
              " ('for', 'IN'),\n",
              " ('about', 'IN'),\n",
              " ('two', 'CD'),\n",
              " ('million', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('Civilisation', 'NN'),\n",
              " ('began', 'VBD'),\n",
              " ('about', 'IN'),\n",
              " ('10,000', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('ago', 'RB'),\n",
              " ('and', 'CC'),\n",
              " ('the', 'DT'),\n",
              " ('rate', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('development', 'NN'),\n",
              " ('has', 'VBZ'),\n",
              " ('been', 'VBN'),\n",
              " ('steadily', 'RB'),\n",
              " ('increasing', 'VBG'),\n",
              " ('If', 'IN'),\n",
              " ('humanity', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('to', 'TO'),\n",
              " ('continue', 'VB'),\n",
              " ('for', 'IN'),\n",
              " ('another', 'DT'),\n",
              " ('million', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('our', 'PRP$'),\n",
              " ('future', 'NN'),\n",
              " ('lies', 'VBZ'),\n",
              " ('in', 'IN'),\n",
              " ('boldly', 'RB'),\n",
              " ('going', 'VBG'),\n",
              " ('where', 'WRB'),\n",
              " ('no', 'DT'),\n",
              " ('one', 'NN'),\n",
              " ('else', 'RB'),\n",
              " ('has', 'VBZ'),\n",
              " ('gone', 'VBN'),\n",
              " ('before', 'RB'),\n",
              " ('I', 'PRP'),\n",
              " ('hope', 'VBP'),\n",
              " ('for', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('best', 'JJS'),\n",
              " ('I', 'PRP'),\n",
              " ('have', 'VBP'),\n",
              " ('to', 'TO'),\n",
              " ('We', 'PRP'),\n",
              " ('have', 'VBP'),\n",
              " ('no', 'DT'),\n",
              " ('other', 'JJ'),\n",
              " ('option', 'NN'),\n",
              " ('The', 'DT'),\n",
              " ('era', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('civilian', 'JJ'),\n",
              " ('space', 'NN'),\n",
              " ('travel', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('coming', 'VBG'),\n",
              " ('What', 'WP'),\n",
              " ('do', 'VBP'),\n",
              " ('you', 'PRP'),\n",
              " ('think', 'VB'),\n",
              " ('it', 'PRP'),\n",
              " ('means', 'VBZ'),\n",
              " ('to', 'TO'),\n",
              " ('us', 'PRP'),\n",
              " ('I', 'PRP'),\n",
              " ('look', 'VBP'),\n",
              " ('forward', 'RB'),\n",
              " ('to', 'TO'),\n",
              " ('space', 'NN'),\n",
              " ('travel', 'NN'),\n",
              " ('I', 'PRP'),\n",
              " ('would', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('one', 'CD'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('first', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('buy', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('ticket', 'NN'),\n",
              " ('I', 'PRP'),\n",
              " ('expect', 'VBP'),\n",
              " ('that', 'IN'),\n",
              " ('within', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('next', 'JJ'),\n",
              " ('hundred', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('we', 'PRP'),\n",
              " ('will', 'MD'),\n",
              " ('be', 'VB'),\n",
              " ('able', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('travel', 'VB'),\n",
              " ('anywhere', 'RB'),\n",
              " ('in', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('solar', 'JJ'),\n",
              " ('system', 'NN'),\n",
              " ('except', 'IN'),\n",
              " ('maybe', 'RB'),\n",
              " ('the', 'DT'),\n",
              " ('outer', 'NN'),\n",
              " ('planets', 'NNS'),\n",
              " ('But', 'CC'),\n",
              " ('travel', 'NN'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('stars', 'NNS'),\n",
              " ('will', 'MD'),\n",
              " ('take', 'VB'),\n",
              " ('a', 'DT'),\n",
              " ('bit', 'NN'),\n",
              " ('longer', 'RBR'),\n",
              " ('I', 'PRP'),\n",
              " ('reckon', 'VBP'),\n",
              " ('in', 'IN'),\n",
              " ('500', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('we', 'PRP'),\n",
              " ('will', 'MD'),\n",
              " ('have', 'VB'),\n",
              " ('visited', 'VBN'),\n",
              " ('some', 'DT'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('nearby', 'JJ'),\n",
              " ('stars', 'NNS'),\n",
              " ('It', 'PRP'),\n",
              " ('won', 'VBD'),\n",
              " ('’', 'NNP'),\n",
              " ('t', 'RB'),\n",
              " ('be', 'VB'),\n",
              " ('like', 'IN'),\n",
              " ('Star', 'NNP'),\n",
              " ('Trek', 'NNP'),\n",
              " ('We', 'PRP'),\n",
              " ('won', 'VBD'),\n",
              " ('’', 'NNP'),\n",
              " ('t', 'NN'),\n",
              " ('be', 'VB'),\n",
              " ('able', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('travel', 'VB'),\n",
              " ('at', 'IN'),\n",
              " ('warp', 'JJ'),\n",
              " ('speed', 'NN'),\n",
              " ('So', 'RB'),\n",
              " ('a', 'DT'),\n",
              " ('round', 'NN'),\n",
              " ('trip', 'NN'),\n",
              " ('will', 'MD'),\n",
              " ('take', 'VB'),\n",
              " ('at', 'IN'),\n",
              " ('least', 'JJS'),\n",
              " ('ten', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('and', 'CC'),\n",
              " ('probably', 'RB'),\n",
              " ('much', 'RB'),\n",
              " ('longer', 'RBR'),\n",
              " ('From', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('book', 'NN'),\n",
              " ('Brief', 'JJ'),\n",
              " ('Answers', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('the', 'DT'),\n",
              " ('Big', 'NNP'),\n",
              " ('Questions', 'NNP'),\n",
              " ('–', 'NNP'),\n",
              " ('Stephen', 'NNP'),\n",
              " ('Hawking', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **7. Word Inflection and Lemmatization**\n",
        "\n",
        "- .words.pluralize(): Pluralizes each word.\n",
        "\n",
        "- .words.singularize(): Converts plural words to singular.\n",
        "\n",
        "- .lemmatize(): Returns the base form of words."
      ],
      "metadata": {
        "id": "45QDn_YETzUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "blob.words.pluralize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnG6weZYTd8E",
        "outputId": "dedeba0a-84d7-4266-93f0-5cd4547ee6e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['SHOULDs', 'WEs', 'COLONISEs', 'SPACEs', 'Ins', 'conclusions', 'we', 'returns', 'toes', 'Einsteins', 'Ifs', 'wes', 'finds', 'some', 'planets', 'ins', 'thes', 'Alphas', 'Centauris', 'systems', 'their', 'images', 'captureds', 'bies', 'some', 'cameras', 'travellings', 'ats', 'some', 'fifths', 'ofs', 'lights', 'speeds', 'wills', 'bes', 'slightlies', 'distorteds', 'dues', 'toes', 'thes', 'effectss', 'ofs', 'specials', 'relativities', 'Its', 'woulds', 'bes', 'thes', 'firsts', 'times', 'some', 'spacecrafts', 'hass', 'flowns', 'fasts', 'enoughs', 'toes', 'sees', 'suches', 'effectss', 'Ins', 'facts', 'Einsteins', '’s', 'ss', 'theories', 'iss', 'centrals', 'toes', 'thes', 'wholes', 'missions', 'Withouts', 'they', 'wes', 'woulds', 'haves', 'neithers', 'laserss', 'nors', 'thes', 'abilities', 'toes', 'performs', 'thes', 'calculationss', 'necessaries', 'fors', 'guidances', 'imagings', 'ands', 'datas', 'transmissions', 'overs', 'twenty-fives', 'trillions', 'miless', 'ats', 'some', 'fifths', 'ofs', 'lights', 'speeds', 'Wes', 'cans', 'sees', 'some', 'pathways', 'betweens', 'those', 'sixteen-year-olds', 'boys', 'dreamings', 'ofs', 'ridings', 'ons', 'some', 'lights', 'beams', 'ands', 'ours', 'owns', 'dreams', 'whiches', 'wes', 'ares', 'plannings', 'toes', 'turns', 'intoes', 'some', 'realities', 'ofs', 'ridings', 'ours', 'owns', 'lights', 'beams', 'toes', 'thes', 'starss', 'Wes', 'ares', 'standings', 'ats', 'thes', 'thresholds', 'ofs', 'some', 'news', 'eras', 'Humen', 'colonisations', 'ons', 'others', 'planetss', 'iss', 'noes', 'longers', 'sciences', 'fictions', 'Its', 'cans', 'bes', 'sciences', 'facts', 'Thes', 'humen', 'races', 'hass', 'existeds', 'ass', 'some', 'separates', 'species', 'fors', 'abouts', 'twoes', 'millions', 'yearss', 'Civilisations', 'begans', 'abouts', '10,000s', 'yearss', 'agoes', 'ands', 'thes', 'rates', 'ofs', 'developments', 'hass', 'beens', 'steadilies', 'increasings', 'Ifs', 'humanities', 'iss', 'toes', 'continues', 'fors', 'anothers', 'millions', 'yearss', 'ours', 'futures', 'liess', 'ins', 'boldlies', 'goings', 'wheres', 'noes', 'ones', 'elses', 'hass', 'gones', 'befores', 'we', 'hopes', 'fors', 'thes', 'bests', 'we', 'haves', 'toes', 'Wes', 'haves', 'noes', 'others', 'options', 'Thes', 'eras', 'ofs', 'civilians', 'spaces', 'travels', 'iss', 'comings', 'Whats', 'does', 'you', 'thinks', 'they', 'meanss', 'toes', 'uss', 'we', 'looks', 'forwards', 'toes', 'spaces', 'travels', 'we', 'woulds', 'bes', 'ones', 'ofs', 'thes', 'firsts', 'toes', 'buys', 'some', 'tickets', 'we', 'expects', 'those', 'withins', 'thes', 'nexts', 'hundreds', 'yearss', 'wes', 'wills', 'bes', 'ables', 'toes', 'travels', 'anywheres', 'ins', 'thes', 'solars', 'systems', 'excepts', 'maybes', 'thes', 'outers', 'planetss', 'Buts', 'travels', 'toes', 'thes', 'starss', 'wills', 'takes', 'some', 'bits', 'longers', 'we', 'reckons', 'ins', '500s', 'yearss', 'wes', 'wills', 'haves', 'visiteds', 'somes', 'ofs', 'thes', 'nearbies', 'starss', 'Its', 'wons', '’s', 'ts', 'bes', 'likes', 'Stars', 'Treks', 'Wes', 'wons', '’s', 'ts', 'bes', 'ables', 'toes', 'travels', 'ats', 'warps', 'speeds', 'Soes', 'some', 'rounds', 'trips', 'wills', 'takes', 'ats', 'leasts', 'tens', 'yearss', 'ands', 'probablies', 'muches', 'longers', 'Froms', 'thes', 'books', 'Briefs', 'Answerss', 'toes', 'thes', 'Bigs', 'Questionss', '–s', 'Stephens', 'Hawkings'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blob.words.singularize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-iTA6lmTpgV",
        "outputId": "07bc9d51-34d4-4a0c-ff5b-265eed01f75e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['SHOULD', 'WE', 'COLONISE', 'SPACE', 'In', 'conclusion', 'I', 'return', 'to', 'Einstein', 'If', 'we', 'find', 'a', 'planet', 'in', 'the', 'Alpha', 'Centaurus', 'system', 'it', 'image', 'captured', 'by', 'a', 'camera', 'travelling', 'at', 'a', 'fifth', 'of', 'light', 'speed', 'will', 'be', 'slightly', 'distorted', 'due', 'to', 'the', 'effect', 'of', 'special', 'relativity', 'It', 'would', 'be', 'the', 'first', 'time', 'a', 'spacecraft', 'ha', 'flown', 'fast', 'enough', 'to', 'see', 'such', 'effect', 'In', 'fact', 'Einstein', '’', 's', 'theory', 'is', 'central', 'to', 'the', 'whole', 'mission', 'Without', 'it', 'we', 'would', 'have', 'neither', 'laser', 'nor', 'the', 'ability', 'to', 'perform', 'the', 'calculation', 'necessary', 'for', 'guidance', 'imaging', 'and', 'datum', 'transmission', 'over', 'twenty-five', 'trillion', 'mile', 'at', 'a', 'fifth', 'of', 'light', 'speed', 'We', 'can', 'see', 'a', 'pathway', 'between', 'that', 'sixteen-year-old', 'boy', 'dreaming', 'of', 'riding', 'on', 'a', 'light', 'beam', 'and', 'my', 'own', 'dream', 'which', 'we', 'are', 'planning', 'to', 'turn', 'into', 'a', 'reality', 'of', 'riding', 'my', 'own', 'light', 'beam', 'to', 'the', 'star', 'We', 'are', 'standing', 'at', 'the', 'threshold', 'of', 'a', 'new', 'era', 'Human', 'colonisation', 'on', 'other', 'planet', 'is', 'no', 'longer', 'science', 'fiction', 'It', 'can', 'be', 'science', 'fact', 'The', 'human', 'race', 'ha', 'existed', 'a', 'a', 'separate', 'species', 'for', 'about', 'two', 'million', 'year', 'Civilisation', 'began', 'about', '10,000', 'year', 'ago', 'and', 'the', 'rate', 'of', 'development', 'ha', 'been', 'steadily', 'increasing', 'If', 'humanity', 'is', 'to', 'continue', 'for', 'another', 'million', 'year', 'my', 'future', 'ly', 'in', 'boldly', 'going', 'where', 'no', 'one', 'else', 'ha', 'gone', 'before', 'I', 'hope', 'for', 'the', 'best', 'I', 'have', 'to', 'We', 'have', 'no', 'other', 'option', 'The', 'era', 'of', 'civilian', 'space', 'travel', 'is', 'coming', 'What', 'do', 'you', 'think', 'it', 'mean', 'to', 'u', 'I', 'look', 'forward', 'to', 'space', 'travel', 'I', 'would', 'be', 'one', 'of', 'the', 'first', 'to', 'buy', 'a', 'ticket', 'I', 'expect', 'that', 'within', 'the', 'next', 'hundred', 'year', 'we', 'will', 'be', 'able', 'to', 'travel', 'anywhere', 'in', 'the', 'solar', 'system', 'except', 'maybe', 'the', 'outer', 'planet', 'But', 'travel', 'to', 'the', 'star', 'will', 'take', 'a', 'bit', 'longer', 'I', 'reckon', 'in', '500', 'year', 'we', 'will', 'have', 'visited', 'some', 'of', 'the', 'nearby', 'star', 'It', 'won', '’', 't', 'be', 'like', 'Star', 'Trek', 'We', 'won', '’', 't', 'be', 'able', 'to', 'travel', 'at', 'warp', 'speed', 'So', 'a', 'round', 'trip', 'will', 'take', 'at', 'least', 'ten', 'year', 'and', 'probably', 'much', 'longer', 'From', 'the', 'book', 'Brief', 'Answer', 'to', 'the', 'Big', 'Question', '–', 'Stephen', 'Hawking'])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **8. Noun Phrase Extraction**\n",
        "\n",
        "- .noun_phrases: Returns a list of noun phrases (important phrases) found in the text."
      ],
      "metadata": {
        "id": "u98OKgO2UXo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('brown')\n",
        "\n",
        "blob.noun_phrases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYWZhmLsUOVj",
        "outputId": "50dd8a61-bc6a-4fc5-9bed-87a1f7fb2802"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WordList(['should we colonise space', 'einstein', 'alpha centauri', 'light speed', 'special relativity', 'such effects', 'einstein', '’ s theory', 'whole mission', 'data transmission', 'twenty-five trillion miles', 'light speed', 'sixteen-year-old boy', 'light beam', 'own dream', 'own light beam', 'new era', 'human colonisation', 'science fiction', 'science fact', 'human race', 'separate species', 'civilisation', 'civilian space travel', 'space travel', 'solar system', 'outer planets', 'nearby stars', '’ t', 'trek', '’ t', 'warp speed', 'round trip', 'brief answers', 'stephen hawking'])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}